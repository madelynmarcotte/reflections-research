Link: https://dl.acm.org/doi/10.1145/3544548.3581524

This week I reviwed the paper "Who Do We Mean When We Talk About Visualization Novices?" by Burns, Lee, Chawla, Peck, and Mahyar. I chose this paper from the inspo folder because I myself am a visualization novice, but am interested in learning more so I thought it would be interesting to see what kinds of traits set pros apart from novices in this field. In this paper, the authors seek to define "novices" in order to determine how to best focus on them as an audience when designing visualizations. They explain that misinterpreting who a novice is could lead to misapplying guidelines and overgeneralizing results. They sought to investigate how visualization researchers define notices and how they use that definition to evaluate visualizations that are intended for novices. For their investigation, they looked for papers that used the words "novice", "non-expert", "laypeople" or "general public" in their title or abstract to assess how those authors defined users in those categories. Through their analysis they found that there is not a standard definition, and there were disagreements and ambiguity between papers. Based on their results, they suggest directions for "inclusively supporting novices in both theory and practice". They recommend that papers should clearly define what they mean by "novice" the same way they would introduce a new term or one that has multiple meanings. They also recommend defining "novice" based on the people that are excluded from that statement, rather than those that are included. They beleive that either of these approaches will help ensure clarity of these studies. The authors also discuss the implication of describing novies in terms of what they are lacking. Deficit models like this have been criticized in many domains because they can be de-humanizing and disproportionately punish minoritized people. I thought this was really interesting and it made me think about the concerns people have with AI due to biases. All forms of technology or means of sharing information can have biases embedded in them. Some are obvious, like training an AI on biased data, but even something that seems smaller, like the phrasing used to refer to novices, can also be imbuing biases in visualizations and other forms of information sharing. 
